{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import copy\n",
    "import re\n",
    "import datetime as dt\n",
    "from time import time\n",
    "from time import sleep\n",
    "from warnings import warn\n",
    "\n",
    "import pyodbc\n",
    "from sqlalchemy import create_engine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Connecting to SQL Server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "SERVER = 'tx-dot-dev-sqlsvr.database.windows.net'\n",
    "DATABASE = 'TX-DOT-DEV-DB'\n",
    "USERNAME = 'sysadmin'\n",
    "PWD = 'N0ru_Mu5k09a9'\n",
    "TABLE = \"Public_Project_Data\"\n",
    "\n",
    "driver= '{ODBC Driver 17 for SQL Server}'  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection_string = 'DRIVER=' + driver + \\\n",
    "                    ';SERVER=' + SERVER + \\\n",
    "                    ';PORT=1433' + \\\n",
    "                    ';DATABASE=' + DATABASE + \\\n",
    "                    ';UID=' + USERNAME + \\\n",
    "                    ';PWD=' + PWD\n",
    "\n",
    "params = urllib.parse.quote_plus(connection_string)\n",
    "engine = create_engine(\"mssql+pyodbc:///?odbc_connect=%s\" % params)\n",
    "sql = 'SELECT MAX([date_accessed]) FROM [stg].[Analysis_Ready_Data]'\n",
    "conn = pyodbc.connect(connection_string)\n",
    "cursor = conn.cursor()\n",
    "df = pd.read_sql(sql, conn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Querying the Latest Date the Data Was Updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_last_date():\n",
    "    conn = pyodbc.connect(connection_string)\n",
    "    cursor = conn.cursor()\n",
    "    cursor.execute('SELECT MAX([date_accessed]) FROM [stg].[Analysis_Ready_Data]')\n",
    "    \n",
    "    for row in cursor:\n",
    "        return row[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2019, 6, 21)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest_date = get_last_date()\n",
    "latest_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Values that will be used to create the url's to scrape data starting from latest Update Date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latest month and year\n",
    "month_init = int(latest_date.month)\n",
    "year_init = int(latest_date.year)\n",
    "\n",
    "if month_init == 12:\n",
    "    month_init = 1\n",
    "    year_init += 1\n",
    "else:\n",
    "    month_init +=1\n",
    "\n",
    "project_type = ['sc','ll','sm'] #state construction, local letting, state maintenance\n",
    "year = [str(i) for i in range(year_init,dt.datetime.today().year+1)]\n",
    "month = [str(i) for i in range(1,13)] #all possible months"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = 'http://www.dot.state.tx.us/insdtdot/orgchart/cmd/cserve/bidtab/'\n",
    "headers = {\"Accept-Language\": \"en-US, en;q=0.5\"}\n",
    "\n",
    "tot_data = []\n",
    "local_table = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrapes All Data From Webpage\n",
    "\n",
    "- Loops through all possible urls from latest update date\n",
    "- Checks that the Tab Page exists\n",
    "- If so adds all the data in the table into tot_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-8d5ebafb6394>, line 17)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-8-8d5ebafb6394>\"\u001b[1;36m, line \u001b[1;32m17\u001b[0m\n\u001b[1;33m    info_table = html_parser.findAll('table')\u001b[0m\n\u001b[1;37m             ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def web_scraper():\n",
    "    tot_data[:] = []\n",
    "    local_table[:] = []\n",
    "    first_month = True\n",
    "    month_cnt = 1\n",
    "    num_req = 0 #number of requests perfomed by html scraper\n",
    "    start_time = time() #start time of running the scraper\n",
    "    for proj_type in project_type:\n",
    "        for yr in year:\n",
    "            while month_cnt < len(month):\n",
    "                if first_month:\n",
    "                    month_cnt = month_init\n",
    "                    first_month = False\n",
    "                response = (requests.get(base_url+proj_type+yr+'0'+month[month_cnt]+'.htm',headers = headers) if(len(month[month_cnt])<2) else requests.get(base_url+proj_type+yr+month[month_cnt]+'.htm',headers = headers))\n",
    "                if response.status_code == 200:\n",
    "                    html_parser = bs(response.text , 'lxml',parse_only = ss('table')\n",
    "                    info_table = html_parser.findAll('table')\n",
    "                    if(len(html_parser.findAll('table')) != 0):\n",
    "                        info_table = html_parser.findAll('table')[1]\n",
    "                        it_rows = info_table.findAll('tr')\n",
    "                        for i in range(1,len(it_rows)):\n",
    "                            web_id = it_rows[i].findAll('td')[0].get_text().strip().replace('/','') + it_rows[i].findAll('td')[1].get_text().strip()\n",
    "                            temp_scrape = bs(requests.get(base_url+web_id + '.htm').text,'lxml',parse_only = ss(['table','title']))\n",
    "                            if(temp_scrape.find('title').get_text() == 'Page Not Found'):\n",
    "                                continue\n",
    "                            else:\n",
    "                                num_req += 1\n",
    "                                print(str(num_req) + \": \" + base_url+web_id + '.htm')\n",
    "                                tot_data.append((temp_scrape.findAll('table')[0:2]))\n",
    "                month_cnt += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conversion to DataFrame\n",
    "\n",
    "- Goes through all the scraped data and adds it to local_table under the correct columns\n",
    "- Goes through both main url data and data from the Tabs url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_df()    \n",
    "    count = 0\n",
    "    for cols in range(0,len(tot_data[0][count].findAll('td')[1:])):\n",
    "        count += 1\n",
    "        if cols%2 != 0:\n",
    "            local_table.append((tot_data[0][0].findAll('td')[cols].get_text().strip(),[]))\n",
    "    local_table.append(('Estimate: ',[]))\n",
    "    local_table.append(('Bid: ',[]))\n",
    "    local_table.append(('Over / Under %' ,[]))\n",
    "    local_table.append(('Bidder: ',[]))\n",
    "    local_table.append(('Winning Bidder: ',[]))\n",
    "    for i in range(0,len(tot_data)):\n",
    "        count = 1\n",
    "        for j in range(1,len(tot_data[i][0].findAll('td'))):\n",
    "            if j%2 == 0:\n",
    "                local_table[count-1][1].append(tot_data[i][0].findAll('td')[j].get_text())\n",
    "                count+=1\n",
    "            if count >= len(local_table) -4:\n",
    "                count = 1\n",
    "        tot_bidders = 0\n",
    "        txt = []\n",
    "        for j in range(0,len(tot_data[i][1].findAll('td'))):\n",
    "            if count == 1:\n",
    "                local_table[15][1].append(tot_data[i][1].findAll('td')[1].get_text().strip())\n",
    "                count+=1\n",
    "            temp = tot_data[i][1].findAll('td')[j].get_text().strip()\n",
    "            tot_bidders += temp.count('Bidder')\n",
    "            txt.append(temp)\n",
    "        bid_count = 1\n",
    "        txt = txt[4:]\n",
    "        winning_bidder = txt[3]\n",
    "        for k in range(0,tot_bidders):\n",
    "            if(k > 0):\n",
    "                for l in range(0,len(local_table)-4):\n",
    "                    local_table[l][1].append(local_table[l][1][len(local_table[l][1])-1])\n",
    "            local_table[16][1].append(txt[bid_count])\n",
    "            local_table[17][1].append(txt[bid_count+1])\n",
    "            local_table[18][1].append(txt[bid_count+2])\n",
    "            local_table[19][1].append(winning_bidder)\n",
    "            bid_count += 4\n",
    "    Dict={title:column for (title,column) in local_table}\n",
    "    df = pd.DataFrame(Dict)\n",
    "    # Pushes Staging Data to Database\n",
    "    df.to_sql(TABLE, engine, if_exists='append')\n",
    "    conn = pyodbc.connect(connection_string)\n",
    "    cursor = conn.cursor()\n",
    "    #Calls Stored Procedure to Store Data Properly\n",
    "    cursor.execute(\"{call dbo.Stage_Raw_Data}\")\n",
    "    cursor.commit()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "web_scraper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_df()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
